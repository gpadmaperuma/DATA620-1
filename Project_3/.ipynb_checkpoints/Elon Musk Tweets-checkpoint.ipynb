{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook's Table of Contents<a name=\"TOC\"></a>\n",
    "<br>\n",
    "<b>This companion notebook is meant to build on the scraping article and article notebook as it covers more scenarios that may come up and provides more examples.</b>\n",
    "\n",
    "0. [Credentials and Authorization](#Section0)\n",
    "<br>Setting up credentials and authorization in order to utilize Tweepy\n",
    "1. [Getting More Information From Tweets](#Section1)\n",
    "<br>How to scrape more information from tweets such as favorite count, retweet count, if they're replying to someone else, if turned on the coordinates of where the tweet came from, etc.\n",
    "2. [Getting User Information From Tweets](#Section2)\n",
    "<br>How to scrape user information from tweets such as their follower count, total amount of tweets, if they're a verified user, location of where account is registered, etc.\n",
    "3. [Scraping Tweets With Advanced Queries](#Section3)\n",
    "<br>How to scrape for tweets using deeper queries such as searching by language of tweets, tweets within a certain location, tweets within specific date ranges, top tweets, etc.\n",
    "4. [Putting It All Together](#Section4)\n",
    "<br>Showcasing how you can mix and match the methods shown above to create queries that'll fulfill your data needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install Tweepy if you don't already have the package\n",
    "# !pip install tweepy\n",
    "\n",
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Credentials and Authorization<a name=\"Section0\"></a>\n",
    "[Return to Table of Contents](#TOC)\n",
    "<br>Tweepy requires credentials before you can utilize its API. The below code helps setup the notebook for authorization. I already have an an article covering setting up Tweepy and getting credentials [here](https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1) if further instructions are needed.\n",
    "\n",
    "You don't necessarily have to create a credentials file, however if you find youself sharing Tweepy code to other parties I recommend it so you don't accidentally share your credentials. Otherwise skip the below cell and just enter your credentials in and have them hardcoded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials \n",
    "\n",
    "consumer_key = \"TroyIuC1l3i3laNlwl5mg\"\n",
    "consumer_secret = \"qYRSTEHzHhTsL0CBcMnXxjqeY5UQ6U4C0kNvmPSG4K4\"\n",
    "access_token = \"1230084602-UtUB4QdlhNkv1aLqrjS3eYoZ96APon5IhjOqBFt\"\n",
    "access_token_secret = \"wscl1nV8gFO4kMhtJy7DjhQKkpJHB1fW5Jzb4RXZq8\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting More Information From Tweets<a name=\"Section1\"></a>\n",
    "[Return to Table of Contents](#TOC)\n",
    "<br>List of information available in tweet object with Tweepy. This is not an exhaustive list but does contain a majority of the available information. If you want an exhaustive list of everything contained in the tweet object there's documentation [here](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object) describing all the attributes. \n",
    "\n",
    "String versions of Id's (e.g., id_str, in_reply_to_status_id_str) are used instead to best keep data integrity as there is a possibility for Id's stored as integers to be cut off.\n",
    "\n",
    "* tweet.user <b>User information is covered in part 2 in greater detail</b><br><br>\n",
    "\n",
    "* tweet.full_text: <b>Text content of tweet when API is told to pull all contents of tweets that have more than 140 characters</b><br><br>\n",
    "\n",
    "* tweet.text: Text content of tweet\n",
    "* tweet.created_at: Date tweet was created\n",
    "* tweet.id_str: Id of tweet\n",
    "* tweet.user.screen_name: Username of tweet's author\n",
    "* tweet.coordinates: Geographic location as reported by user or client. May be null that is why extract_coordinates function below was created\n",
    "* tweet.place: Indicates place associated with tweet where user signed up with like Las Vegas, NV. May be null that so extract_place function below was created\n",
    "* tweet.retweet_count: Count of retweets\n",
    "* tweet.favorite_count: Count of favorites\n",
    "* tweet.lang: Indicates a BCP 47 language identifier corresponding to machine detected language of tweet text.\n",
    "* tweet.source: Source where tweet was posted through. Ex: Twitter Web Client\n",
    "* tweet.in_reply_to_status_id_str: If a tweet is a reply, the original tweet's id. Can be null if tweet is not a reply\n",
    "* tweet.in_reply_to_user_id_str: If a tweet is a reply, string representation of original tweet's user id\n",
    "* tweet.is_quote_status: If tweet is a quote tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function created to extract coordinates from tweet if it has coordinate info\n",
    "# Tweets tend to have null so important to run check\n",
    "# Make sure to run this cell as it is used in a lot of different functions below\n",
    "def extract_coordinates(row):\n",
    "    if row['Tweet Coordinates']:\n",
    "        return row['Tweet Coordinates']['coordinates']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function created to extract place such as city, state or country from tweet if it has place info\n",
    "# Tweets tend to have null so important to run check\n",
    "# Make sure to run this cell as it is used in a lot of different functions below\n",
    "def extract_place(row):\n",
    "    if row['Place Info']:\n",
    "        return row['Place Info'].full_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_user_tweets(username, max_tweets):\n",
    "    # Creation of query method using parameters\n",
    "    tweets = tweepy.Cursor(api.user_timeline,id=username).items(max_tweets)\n",
    "\n",
    "    # List comprehension pulling chosen tweet information from tweets iterable object\n",
    "    # Add or remove tweet information you want in the below list comprehension\n",
    "    tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.user.screen_name, tweet.coordinates,\n",
    "                   tweet.place, tweet.retweet_count, tweet.favorite_count, tweet.lang,\n",
    "                   tweet.source, tweet.in_reply_to_status_id_str, \n",
    "                    tweet.in_reply_to_user_id_str, tweet.is_quote_status,\n",
    "                    ] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets_list\n",
    "    # Add or remove columns as you remove tweet information\n",
    "    tweets_df = pd.DataFrame(tweets_list,columns=['Tweet Text', 'Tweet Datetime', 'Tweet Id', 'Twitter @ Name', 'Tweet Coordinates', 'Place Info',\n",
    "                                                 'Retweets', 'Favorites', 'Language', 'Source', 'Replied Tweet Id',\n",
    "                                                  'Replied Tweet User Id Str', 'Quote Status Bool'])\n",
    "    \n",
    "    # Checks if there are coordinates attached to tweets, if so extracts them\n",
    "    tweets_df['Tweet Coordinates'] = tweets_df.apply(extract_coordinates,axis=1)\n",
    "    \n",
    "    # Checks if there is place information available, if so extracts them\n",
    "    tweets_df['Place Info'] = tweets_df.apply(extract_place,axis=1)\n",
    "    \n",
    "    # Uncomment/comment below lines to decide between creating csv or excel file \n",
    "    tweets_df.to_csv('{}-tweets.csv'.format(username), sep=',', index = False)\n",
    "#     tweets_df.to_excel('{}-tweets.xlsx'.format(username), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating example username to scrape from\n",
    "username = 'elonmusk'\n",
    "\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "max_tweets = 1000\n",
    "\n",
    "# Function will scrape username, attempt to pull max_tweet amount, and create csv/excel file from data.\n",
    "scrape_user_tweets(username,max_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
