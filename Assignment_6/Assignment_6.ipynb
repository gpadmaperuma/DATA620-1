{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "normal-reflection",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-abraham",
   "metadata": {},
   "source": [
    "### Author : Omer Ozeren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-temperature",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-foster",
   "metadata": {},
   "source": [
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-destiny",
   "metadata": {},
   "source": [
    "### Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-parameter",
   "metadata": {},
   "source": [
    "Please click [here](http://archive.ics.uci.edu/ml/datasets/Spambase) to see the spam data set, I used files spambase.names & spambase.data. The spambase.data is the actual data and spambase.names is the  column names and the directions to construct the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-works",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import sklearn.metrics as sm\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
